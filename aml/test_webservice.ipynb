{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python362jvsc74a57bd0b325c1708bfb23a99d2da8d183818b06719bc1d8ed3a28f4f7618f1ddb204538",
   "display_name": "Python 3.6.2 64-bit ('rwe-poc-vbm-proper': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n",
    "experiment = Experiment(ws, 'trump-tweets-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment, Model, Run\n",
    "from azureml.core.webservice import AksWebservice, LocalWebservice\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "service_name = \"trump-tweets-scoring-aml\"\n",
    "model_name = \"trump-tweet-classification\"\n",
    "\n",
    "# getting last model\n",
    "model = next(iter(Model.list(workspace=ws, name=model_name, latest=True)), None,)\n",
    "\n",
    "environment = Environment(\"trump-tweet-inferencing\")\n",
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_conda_package(\"scikit-learn\")\n",
    "conda_dep.add_pip_package(\"azureml-sdk\")\n",
    "environment.python.conda_dependencies = conda_dep\n",
    "\n",
    "aks_target = AksCompute(ws, \"trump-tweets-inf\")\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   source_directory=\"./script_folder/04_deploy/\",\n",
    "                                   environment=environment)\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "raw_data = \"['The media is spreading fake news!']\"\n",
    "\n",
    "input_data = \"{\\\"data\\\": [\" + raw_data + \"]}\"\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "scoring_uri = \"http://localhost:6789/score\"\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"Should be predicted as '2'\")\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "request = [\"The media is spreading fake news!\"]\n",
    "input_json = json.dumps({\"data\": request})\n",
    "predictions = service.run(input_data = input_json)\n",
    "response = json.loads(predictions)\n",
    "for item in sorted(response.items(), key=lambda x: x[1], reverse=True):\n",
    "    k, v = item\n",
    "    print (\"{:<25} {:<4} \".format(k, round(v,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright (c) 2021, Microsoft\n",
    "\n",
    "Permission to use, copy, modify, and/or distribute this software for any\n",
    "purpose with or without fee is hereby granted, provided that the above\n",
    "copyright notice and this permission notice appear in all copies.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\n",
    "INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\n",
    "LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\n",
    "OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\n",
    "PERFORMANCE OF THIS SOFTWARE.\n",
    "\n",
    "DO NOT USE IN PRODUCTION ENVIRONMENTS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n",
    "experiment = Experiment(ws, 'trump-tweets-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Computes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your training CPU cluster\n",
    "cpu_cluster_name = \"trump-tweets-cpu\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=10,\n",
    "                                                           min_nodes=0,\n",
    "                                                           idle_seconds_before_scaledown=900)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"trump-tweets-pl\"\n",
    "try:  \n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',\n",
    "                                                               max_nodes=2,\n",
    "                                                               min_nodes=0,\n",
    "                                                               idle_seconds_before_scaledown=900)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'trump-tweets-inf'\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Use the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace=ws, \n",
    "                                      name=aks_name, \n",
    "                                      provisioning_configuration=prov_config)\n",
    "\n",
    "if aks_target.get_status() != \"Succeeded\":\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataPath Pipeline Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.pipeline.core import PipelineParameter\n",
    "\n",
    "datapath = DataPath(datastore=datastore, path_on_datastore='upload')\n",
    "data_path_pipeline_param = PipelineParameter(name=\"input_data\", default_value=datapath)\n",
    "datapath_input = (data_path_pipeline_param, DataPathComputeBinding(mode='mount'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define PrepStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.pipeline.core import Pipeline, PublishedPipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_pip_package(\"pandas\")\n",
    "conda_dep.add_pip_package(\"azureml-sdk\")\n",
    "\n",
    "data_prep_rcfg = RunConfiguration(conda_dependencies=conda_dep)\n",
    "\n",
    "prep_step = PythonScriptStep(\n",
    "    name=\"data_prep_step\",\n",
    "    script_name=\"prepare.py\",\n",
    "    source_directory=\"./script_folder/01_prep\",\n",
    "    arguments=[\"--input\", datapath_input],\n",
    "    inputs=[datapath_input],\n",
    "    compute_target=pipeline_cluster,\n",
    "    runconfig = data_prep_rcfg,\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define HyperDriveStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'SKLearn' estimator is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or the AzureML-Tutorial curated environment.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.dataset import Dataset\r\n",
    "from azureml.core import ScriptRunConfig, Environment\r\n",
    "from azureml.train.sklearn import SKLearn\r\n",
    "from azureml.train.hyperdrive import (GridParameterSampling, RandomParameterSampling, BanditPolicy,\r\n",
    "                                      HyperDriveConfig, PrimaryMetricGoal, BanditPolicy, normal,\r\n",
    "                                      uniform, choice)\r\n",
    "from azureml.pipeline.steps import HyperDriveStep\r\n",
    "from azureml.pipeline.core import PipelineData, TrainingOutput\r\n",
    "\r\n",
    "proper_ds = Dataset.get_by_name(ws, name='trump-tweets-prepared')\r\n",
    "proper_ds_named = proper_ds.as_named_input('trumptweetsprepared')\r\n",
    "\r\n",
    "environment = Environment(\"proper-training\")\r\n",
    "environment.python.conda_dependencies = CondaDependencies.create(\r\n",
    "    conda_packages=[\"scikit-learn\", \"pandas\"], pip_packages=[\"azureml-defaults\",],\r\n",
    ")\r\n",
    "\r\n",
    "#src = ScriptRunConfig(source_directory=\"./script_folder/02_train\",\r\n",
    "#                      script='training.py',\r\n",
    "#                      compute_target=cpu_cluster_name,\r\n",
    "#                      environment=environment)\r\n",
    "\r\n",
    "est = SKLearn(compute_target=cpu_cluster_name,\r\n",
    "              entry_script='training.py',\r\n",
    "              source_directory=\"./script_folder/02_train\",\r\n",
    "              conda_packages=['matplotlib'],\r\n",
    "              pip_packages=['azureml-dataset-runtime[pandas,fuse]'])\r\n",
    "\r\n",
    "param_sampling = RandomParameterSampling( {\r\n",
    "        \"min_doc_freq\": choice(range(2,10)),\r\n",
    "        \"max_doc_freq\": uniform(0.4,0.7),\r\n",
    "        \"n_estimators\": choice(range(1,1000)),\r\n",
    "        \"min_class_frequency\": choice(range(1,50))\r\n",
    "    }\r\n",
    ")\r\n",
    "\r\n",
    "hd_config = HyperDriveConfig(estimator=est, \r\n",
    "                            hyperparameter_sampling=param_sampling,\r\n",
    "                            policy=BanditPolicy(evaluation_interval=3, slack_amount=0.05),\r\n",
    "                            primary_metric_name='Accuracy', \r\n",
    "                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \r\n",
    "                            max_total_runs=10,\r\n",
    "                            max_concurrent_runs=4)\r\n",
    "\r\n",
    "metrics_data = PipelineData(name='metrics_data',\r\n",
    "                            datastore=datastore,\r\n",
    "                            pipeline_output_name='metrics_output',\r\n",
    "                            training_output=TrainingOutput(type=\"Metrics\"))\r\n",
    "\r\n",
    "saved_model = PipelineData(name='saved_model',\r\n",
    "                            datastore=datastore,\r\n",
    "                            pipeline_output_name='model_output',\r\n",
    "                            is_directory=True,\r\n",
    "                            training_output=TrainingOutput(type='Model'))\r\n",
    "\r\n",
    "hd_step = HyperDriveStep(\r\n",
    "    name='hyperdrive_step',\r\n",
    "    hyperdrive_config=hd_config,\r\n",
    "    estimator_entry_script_arguments=['--input-data', proper_ds_named],\r\n",
    "    inputs=[proper_ds_named],\r\n",
    "    outputs=[metrics_data, saved_model],\r\n",
    "    allow_reuse=True)\r\n",
    "\r\n",
    "hd_step.run_after(prep_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Register Model and Deploy Endpoint Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_pip_package(\"azureml-sdk\")\n",
    "\n",
    "register_model_rcfg = RunConfiguration(conda_dependencies=conda_dep)\n",
    "\n",
    "register_model_step = PythonScriptStep(script_name='register_model.py',\n",
    "                                       source_directory=\"./script_folder/03_register_model\",\n",
    "                                       name=\"register_model_step\",\n",
    "                                       compute_target=pipeline_cluster,\n",
    "                                       allow_reuse=True,\n",
    "                                       runconfig=register_model_rcfg)\n",
    "\n",
    "register_model_step.run_after(hd_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_pip_package(\"azureml-sdk\")\n",
    "\n",
    "deploy_rcfg = RunConfiguration(conda_dependencies=conda_dep)\n",
    "\n",
    "deploy_step = PythonScriptStep(\n",
    "    name=\"deploy_step\",\n",
    "    script_name=\"deploy.py\",\n",
    "    source_directory=\"./script_folder/04_deploy\",\n",
    "    arguments=[],\n",
    "    inputs=[],\n",
    "    compute_target=pipeline_cluster,\n",
    "    runconfig = deploy_rcfg,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "deploy_step.run_after(register_model_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Run / Publish Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore\n",
      ">>>   2021/04/19 07:59:33 Successfully mounted azureml-blobstore-235e526e-18a0-41b8-81aa-3b9bf4be3c17 container from mlwteststorage6cc78d867d account at /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore\n",
      ">>>   2021/04/19 07:59:33 No unmanaged file systems configured\n",
      ">>>   2021/04/19 07:59:33 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/04/19 07:59:33 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/04/19 07:59:33 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs\n",
      ">>>   2021/04/19 07:59:33 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/logs\n",
      ">>>   2021/04/19 07:59:34 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/outputs\n",
      ">>>   2021/04/19 07:59:34 Starting output-watcher...\n",
      ">>>   2021/04/19 07:59:34 Single file input dataset is enabled.\n",
      ">>>   2021/04/19 07:59:34 Start to pulling docker image: mlwtest82f49cc9.azurecr.io/azureml/azureml_b725f2a42834d8243d544b41c46cabe3\n",
      ">>>   2021/04/19 07:59:34 Start pull docker image: mlwtest82f49cc9.azurecr.io\n",
      ">>>   2021/04/19 07:59:34 Getting credentials for image mlwtest82f49cc9.azurecr.io/azureml/azureml_b725f2a42834d8243d544b41c46cabe3 with url mlwtest82f49cc9.azurecr.io\n",
      ">>>   2021/04/19 07:59:34 Container registry is ACR.\n",
      ">>>   2021/04/19 07:59:34 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/04/19 07:59:34 Getting ACR Credentials from EMS for environment Experiment trump-tweets-classification Environment:Autosave_2021-03-24T13:41:54Z_fd1fe281\n",
      ">>>   2021/04/19 07:59:34 Requesting XDS for registry details.\n",
      ">>>   2021/04/19 07:59:34 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/aed9cf00-533b-4fbd-904b-ac7d3d4179fd/resourceGroups/rg-ai-test/workspaces/mlw-test/clusters/trump-tweets-pl/nodes/tvmps_18e0528f244f7a9c3b82a30a2d2008bc5c21250665e2c9dd5b9bdd89e6d172d8_d?api-version=2018-02-01\n",
      ">>>   2021/04/19 07:59:34 Got container registry details from credentials service for registry address: mlwtest82f49cc9.azurecr.io.\n",
      ">>>   2021/04/19 07:59:34 Writing ACR Details to file...\n",
      ">>>   2021/04/19 07:59:34 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/04/19 07:59:34 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2021/04/19 07:59:34 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/04/19 07:59:34 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/04/19 07:59:34 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   2021/04/19 07:59:34 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/04/19 07:59:34 EMS returned mlwtest82f49cc9.azurecr.io for environment Experiment trump-tweets-classification Environment\n",
      ">>>   2021/04/19 07:59:34 start login to the docker registry\n",
      ">>>   2021/04/19 07:59:34 Successfully logged into the docker registry.\n",
      ">>>   2021/04/19 07:59:34 Start run pull docker image command\n",
      ">>>   2021/04/19 07:59:35 Pull docker image succeeded.\n",
      ">>>   2021/04/19 07:59:35 Pull docker image time: 615.588368ms\n",
      ">>>   \n",
      ">>>   2021/04/19 07:59:35 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/04/19 07:59:35 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/04/19 07:59:35 Setting the memory limit for docker container to be 13674 MB\n",
      ">>>   2021/04/19 07:59:35 The env variable file size is 36142 bytes\n",
      ">>>   2021/04/19 07:59:35 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/04/19 07:59:35 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,1ab865ad-7093-49c5-b97e-5829e0486ba0,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/certs:/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd:/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0:/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/1ab865ad-7093-49c5-b97e-5829e0486ba0/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/1ab865ad-7093-49c5-b97e-5829e0486ba0/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/config/.batchai.envlist,--shm-size,2g\n",
      ">>>   2021/04/19 07:59:35 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/1ab865ad-7093-49c5-b97e-5829e0486ba0/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/1ab865ad-7093-49c5-b97e-5829e0486ba0/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/04/19 07:59:35 the binding /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0:/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0 \n",
      ">>>   2021/04/19 07:59:35 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,1ab865ad-7093-49c5-b97e-5829e0486ba0,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/config/.batchai.envlist,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0:/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0,-v,/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd:/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd,-v,/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/certs:/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/certs\n",
      ">>>   2021/04/19 07:59:35 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 1ab865ad-7093-49c5-b97e-5829e0486ba0 -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/config/.batchai.envlist --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0:/mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0 -v /mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd:/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd -v /mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/certs:/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/certs -d -it --privileged --net=host mlwtest82f49cc9.azurecr.io/azureml/azureml_b725f2a42834d8243d544b41c46cabe3\n",
      ">>>   2021/04/19 07:59:35 Check if container 1ab865ad-7093-49c5-b97e-5829e0486ba0 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/04/19 07:59:35 Check if container 1ab865ad-7093-49c5-b97e-5829e0486ba0 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/04/19 07:59:35 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/04/19 07:59:35 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/04/19 07:59:35 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-a58e0a65ca1a4f4ec80161924c5b66c7-936b7facb50fe046-01 -sshRequired=false] \n",
      ">>>   2021/04/19 07:59:35 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-a58e0a65ca1a4f4ec80161924c5b66c7-936b7facb50fe046-01 -sshRequired=false] \n",
      ">>>   2021/04/19 07:59:36 Container ssh is not required for job type.\n",
      ">>>   2021/04/19 07:59:36 Starting docker container succeeded.\n",
      ">>>   2021/04/19 07:59:36 Starting docker container succeeded.\n",
      ">>>   2021/04/19 07:59:36 Disk space after starting docker container: 24441MB\n",
      ">>>   2021/04/19 07:59:36 Begin execution of runSpecialJobTask\n",
      ">>>   2021/04/19 07:59:36 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs\n",
      ">>>   2021/04/19 07:59:36 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_ceff46719d0119a17f36fe694c502d18/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0-setup/job_prep.py --snapshots '[{\"Id\":\"657ffbe2-4ab8-47d8-aafe-578c1fa34d91\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/04/19 07:59:36 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs/65_job_prep-tvmps_18e0528f244f7a9c3b82a30a2d2008bc5c21250665e2c9dd5b9bdd89e6d172d8_d.txt\n",
      ">>>   2021/04/19 07:59:36 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/azureml_compute_logs/65_job_prep-tvmps_18e0528f244f7a9c3b82a30a2d2008bc5c21250665e2c9dd5b9bdd89e6d172d8_d.txt\n",
      ">>>   2021/04/19 07:59:36 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0;/azureml-envs/azureml_ceff46719d0119a17f36fe694c502d18/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0-setup/job_prep.py --snapshots '[{\"Id\":\"657ffbe2-4ab8-47d8-aafe-578c1fa34d91\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/04/19 07:59:36 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/04/19 07:59:36 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-a58e0a65ca1a4f4ec80161924c5b66c7-bea88f4dd5b742ed-01 -t 1ab865ad-7093-49c5-b97e-5829e0486ba0 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/10612083-ad44-444f-a59e-57e6e6a14123/job-1/1ab865ad-7093-49c5-b_dfc73f48-94be-4120-98ac-0b6bc0f66ed6/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0;/azureml-envs/azureml_ceff46719d0119a17f36fe694c502d18/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlw-test/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0/mounts/workspaceblobstore/azureml/1ab865ad-7093-49c5-b97e-5829e0486ba0-setup/job_prep.py --snapshots '[{\"Id\":\"657ffbe2-4ab8-47d8-aafe-578c1fa34d91\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/04/19 07:59:37 Attempt 1 of http call to https://westeurope.experiments.azureml.net/history/v1.0/private/subscriptions/aed9cf00-533b-4fbd-904b-ac7d3d4179fd/resourceGroups/rg-ai-test/providers/Microsoft.MachineLearningServices/workspaces/mlw-test/runs/1ab865ad-7093-49c5-b97e-5829e0486ba0/spans\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:37.052774] Entering job preparation.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:38.603318] Starting job preparation.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:38.603387] Extracting the control code.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:38.625492] fetching and extracting the control code on master node.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:38.625539] Starting extract_project.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:38.625584] Starting to extract zip file.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.379784] Finished extracting zip file.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.524772] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.524849] Start fetching snapshots.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.524895] Start fetching snapshot.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.524915] Retrieving project from snapshot: 657ffbe2-4ab8-47d8-aafe-578c1fa34d91\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 49\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.784295] Finished fetching snapshot.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.784353] Finished fetching snapshots.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.784365] Finished extract_project.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.828927] Finished fetching and extracting the control code.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.832700] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.833950] Start run_history_prep.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.885316] Entering context manager injector.\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.963551] downloadDataStore completed\n",
      ">>>   2021/04/19 07:59:40 runSpecialJobTask: preparation: [2021-04-19T07:59:39.965752] Job preparation is complete.\n",
      ">>>   2021/04/19 07:59:40 Execution of runSpecialJobTask completed\n",
      ">>>   2021/04/19 07:59:40 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/04/19 07:59:40 Process Exiting with Code:  0\n",
      ">>>   2021/04/19 07:59:40 All App Insights Logs was send successfully\n",
      ">>>   \n",
      "2021-04-19T07:59:40Z 127.0.0.1 slots=2 max-slots=2\n",
      "2021-04-19T07:59:40Z launching Custom job\n",
      "2021-04-19T07:59:49Z job exited with code 1\n",
      "2021-04-19T07:59:50Z PostJobNodeHealthCheck\n",
      "2021-04-19T07:59:50Z Executing 'Post job node health check' on 10.0.0.5\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_18e0528f244f7a9c3b82a30a2d2008bc5c21250665e2c9dd5b9bdd89e6d172d8_d.txt\n",
      "===============================================================================================================\n",
      "[2021-04-19T07:59:51.366517] Entering job release\n",
      "[2021-04-19T07:59:53.215721] Starting job release\n",
      "[2021-04-19T07:59:53.224067] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 187\n",
      "[2021-04-19T07:59:53.238193] job release stage : upload_datastore starting...\n",
      "[2021-04-19T07:59:53.239180] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-04-19T07:59:53.239332] job release stage : execute_job_release starting...\n",
      "[2021-04-19T07:59:53.240608] Entering context manager injector.\n",
      "[2021-04-19T07:59:53.242480] job release stage : upload_datastore completed...\n",
      "[2021-04-19T07:59:53.248539] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-04-19T07:59:53.250279] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-04-19T07:59:53.416797] job release stage : send_run_telemetry starting...\n",
      "[2021-04-19T07:59:53.446498] job release stage : execute_job_release completed...\n",
      "[2021-04-19T07:59:53.837783] get vm size and vm region successfully.\n",
      "[2021-04-19T07:59:54.007167] get compute meta data successfully.\n",
      "[2021-04-19T07:59:54.253718] post artifact meta request successfully.\n",
      "[2021-04-19T07:59:54.312945] upload compute record artifact successfully.\n",
      "[2021-04-19T07:59:54.313060] job release stage : send_run_telemetry completed...\n",
      "[2021-04-19T07:59:54.313481] Job release is complete\n",
      "\n",
      "StepRun(deploy_step) Execution Summary\n",
      "=======================================\n",
      "StepRun( deploy_step ) Status: Failed\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"UserTrainingScriptFailed\"\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"a5a74abd014c2d93\"\n    },\n    \"environment\": \"westeurope\",\n    \"location\": \"westeurope\",\n    \"time\": \"2021-04-19T08:00:04.140642Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"UserTrainingScriptFailed\\\"\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"a5a74abd014c2d93\\\"\\n    },\\n    \\\"environment\\\": \\\"westeurope\\\",\\n    \\\"location\\\": \\\"westeurope\\\",\\n    \\\"time\\\": \\\"2021-04-19T08:00:04.140642Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-497732e5c8a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpipeline_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpipeline_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#published_pipeline = pipeline_run.publish_pipeline(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rwe-poc-vbm-proper\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    293\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[1;32m--> 295\u001b[1;33m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    296\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                                 \u001b[1;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rwe-poc-vbm-proper\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[1;32m--> 737\u001b[1;33m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    738\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rwe-poc-vbm-proper\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    823\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"UserTrainingScriptFailed\"\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"a5a74abd014c2d93\"\n    },\n    \"environment\": \"westeurope\",\n    \"location\": \"westeurope\",\n    \"time\": \"2021-04-19T08:00:04.140642Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"UserTrainingScriptFailed\\\"\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"a5a74abd014c2d93\\\"\\n    },\\n    \\\"environment\\\": \\\"westeurope\\\",\\n    \\\"location\\\": \\\"westeurope\\\",\\n    \\\"time\\\": \\\"2021-04-19T08:00:04.140642Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "steps = [prep_step, hd_step, register_model_step, deploy_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "pipeline_run = experiment.submit(pipeline)\n",
    "pipeline_run.wait_for_completion()\n",
    "\n",
    "#published_pipeline = pipeline_run.publish_pipeline(\n",
    "#     name=\"Trump Tweets Classification Pipeline\",\n",
    "#     description=\"Re-run prep, training and deploying when new data arrives.\",\n",
    "#     version=\"0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Regression - Automobile Price Prediction (Basic) 08-11-2020-02-12, '46184478-663f-4a88-86c1-f092aeadf6b9', None\n"
     ]
    }
   ],
   "source": [
    "#published_pipelines = PublishedPipeline.list(ws)\n",
    "#for published_pipeline in published_pipelines:\n",
    "#    print(f\"{published_pipeline.name}, '{published_pipeline.id}', { published_pipeline.version}\")\n",
    "#PublishedPipeline.get(ws, id=\"d37e9c60-5316-40b5-87af-0e9de702b500\").disable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit ('rwe-poc-vbm-proper': conda)",
   "name": "python362jvsc74a57bd07a90f65280171735f32f8d896a7a093ac009bd1472172dbbce51db729619213b"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{"cells":[{"cell_type":"code","source":["# Copyright (c) 2021, Microsoft\n\n# Permission to use, copy, modify, and/or distribute this software for any\n# purpose with or without fee is hereby granted, provided that the above\n# copyright notice and this permission notice appear in all copies.\n\n# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\n# INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\n# LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\n# OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\n# PERFORMANCE OF THIS SOFTWARE.\n#\n# DO NOT USE IN PRODUCTION ENVIRONMENTS."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f0fafa6-f8f9-4030-a257-621e96d9f236"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%pip install pandas==1.1.0 azureml-sdk"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"180affd6-e910-4a56-ae23-cb0dc1ddced1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting pandas==1.1.0\n  Downloading pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\nCollecting azureml-sdk\n  Downloading azureml_sdk-1.26.0-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from pandas==1.1.0) (2.8.1)\nRequirement already satisfied: pytz&gt;=2017.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from pandas==1.1.0) (2019.3)\nRequirement already satisfied: numpy&gt;=1.15.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from pandas==1.1.0) (1.18.1)\nCollecting azureml-dataset-runtime[fuse]~=1.26.0\n  Downloading azureml_dataset_runtime-1.26.0-py3-none-any.whl (3.4 kB)\nCollecting azureml-train~=1.26.0\n  Downloading azureml_train-1.26.0-py3-none-any.whl (3.3 kB)\nCollecting azureml-train-automl-client~=1.26.0\n  Downloading azureml_train_automl_client-1.26.0-py3-none-any.whl (119 kB)\nCollecting azureml-pipeline~=1.26.0\n  Downloading azureml_pipeline-1.26.0-py3-none-any.whl (3.7 kB)\nCollecting azureml-core~=1.26.0\n  Downloading azureml_core-1.26.0-py3-none-any.whl (2.2 MB)\nRequirement already satisfied: six&gt;=1.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas==1.1.0) (1.14.0)\nCollecting azureml-dataprep&lt;2.14.0a,&gt;=2.13.0a\n  Downloading azureml_dataprep-2.13.2-py3-none-any.whl (39.4 MB)\nRequirement already satisfied: pyarrow&lt;2.0.0,&gt;=0.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-dataset-runtime[fuse]~=1.26.0-&gt;azureml-sdk) (1.0.1)\nCollecting fusepy&lt;4.0.0,&gt;=3.0.1; extra == &#34;fuse&#34;\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting azureml-train-core~=1.26.0\n  Downloading azureml_train_core-1.26.0-py3-none-any.whl (8.6 MB)\nCollecting azureml-telemetry~=1.26.0\n  Downloading azureml_telemetry-1.26.0-py3-none-any.whl (30 kB)\nCollecting azureml-automl-core~=1.26.0\n  Downloading azureml_automl_core-1.26.0-py3-none-any.whl (200 kB)\nCollecting azureml-pipeline-core~=1.26.0\n  Downloading azureml_pipeline_core-1.26.0-py3-none-any.whl (309 kB)\nCollecting azureml-pipeline-steps~=1.26.0\n  Downloading azureml_pipeline_steps-1.26.0-py3-none-any.whl (68 kB)\nCollecting jsonpickle\n  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting azure-common&gt;=1.1.12\n  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: PyJWT&lt;3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (2.0.1)\nCollecting azure-mgmt-keyvault&lt;7.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting ruamel.yaml&gt;=0.15.35\n  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\nRequirement already satisfied: pyopenssl&lt;21.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (19.1.0)\nCollecting azure-mgmt-containerregistry&gt;=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nRequirement already satisfied: msrest&gt;=0.5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (0.6.19)\nRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (2.8)\nRequirement already satisfied: urllib3&gt;=1.23 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (1.25.8)\nCollecting azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1\n  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nRequirement already satisfied: jmespath in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (0.10.0)\nCollecting azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0\n  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting adal&gt;=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting msrestazure&gt;=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.19.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (2.22.0)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting azure-graphrbac&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting SecretStorage\n  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: docker in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (4.4.1)\nCollecting azure-identity&lt;1.5.0,&gt;=1.2.0\n  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\nCollecting azureml-dataprep-native&lt;33.0.0,&gt;=32.0.0\n  Downloading azureml_dataprep_native-32.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\nCollecting azureml-dataprep-rslex&lt;1.12.0a,&gt;=1.11.0dev0\n  Downloading azureml_dataprep_rslex-1.11.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\nRequirement already satisfied: cloudpickle&lt;2.0.0,&gt;=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-dataprep&lt;2.14.0a,&gt;=2.13.0a-&gt;azureml-dataset-runtime[fuse]~=1.26.0-&gt;azureml-sdk) (1.4.1)\nCollecting dotnetcore2&lt;3.0.0,&gt;=2.1.14\n  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\nCollecting azureml-train-restclients-hyperdrive~=1.26.0\n  Downloading azureml_train_restclients_hyperdrive-1.26.0-py3-none-any.whl (19 kB)\nCollecting applicationinsights\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\nCollecting importlib-metadata; python_version &lt; &#34;3.8&#34;\n  Downloading importlib_metadata-4.0.0-py3-none-any.whl (16 kB)\nCollecting ruamel.yaml.clib&gt;=0.1.2; platform_python_implementation == &#34;CPython&#34; and python_version &lt; &#34;3.10&#34;\n  Downloading ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547 kB)\nRequirement already satisfied: isodate&gt;=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (0.6.0)\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (1.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (2020.12.5)\nRequirement already satisfied: cffi!=1.11.3,&gt;=1.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (1.14.0)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.19.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (2.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.19.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (3.0.4)\nRequirement already satisfied: pyasn1&gt;=0.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from ndg-httpsclient-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (0.4.8)\nCollecting jeepney&gt;=0.6\n  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from docker-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (0.56.0)\nRequirement already satisfied: azure-core&lt;2.0.0,&gt;=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azure-identity&lt;1.5.0,&gt;=1.2.0-&gt;azureml-dataprep&lt;2.14.0a,&gt;=2.13.0a-&gt;azureml-dataset-runtime[fuse]~=1.26.0-&gt;azureml-sdk) (1.10.0)\nCollecting msal&lt;2.0.0,&gt;=1.3.0\n  Downloading msal-1.11.0-py2.py3-none-any.whl (63 kB)\nCollecting msal-extensions~=0.2.2\n  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\nCollecting distro&gt;=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\nRequirement already satisfied: typing-extensions&gt;=3.6.4; python_version &lt; &#34;3.8&#34; in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;jsonpickle-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (3.7.4.3)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (3.1.0)\nRequirement already satisfied: pycparser in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from cffi!=1.11.3,&gt;=1.8-&gt;cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (2.19)\nCollecting portalocker~=1.0; platform_system != &#34;Windows&#34;\n  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\nBuilding wheels for collected packages: fusepy\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status &#39;done&#39;\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=de34d723a9f01b43a629a83228d7ccd7794a9c1857f2413df586e49f19adadbc\n  Stored in directory: /root/.cache/pip/wheels/89/07/84/a5ebfafeefbbc56ceda9d6935a54a8be7a4eccf4ea7e9bf980\nSuccessfully built fusepy\nERROR: petastorm 0.9.7 requires pyspark&gt;=2.1.0, which is not installed.\nERROR: mlflow 1.13.1 requires alembic&lt;=1.4.1, which is not installed.\nERROR: mlflow 1.13.1 requires prometheus-flask-exporter, which is not installed.\nERROR: mlflow 1.13.1 requires sqlalchemy, which is not installed.\nInstalling collected packages: pandas, msal, portalocker, msal-extensions, azure-identity, azureml-dataprep-native, azureml-dataprep-rslex, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, adal, msrestazure, azureml-train-restclients-hyperdrive, applicationinsights, zipp, importlib-metadata, jsonpickle, azure-common, azure-mgmt-keyvault, azure-mgmt-authorization, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-containerregistry, azure-mgmt-resource, backports.weakref, backports.tempfile, azure-mgmt-storage, pathspec, contextlib2, ndg-httpsclient, azure-graphrbac, jeepney, SecretStorage, azureml-core, azureml-telemetry, azureml-train-core, azureml-train, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-core, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.0.1\n    Uninstalling pandas-1.0.1:\n      Successfully uninstalled pandas-1.0.1\nSuccessfully installed SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.9 azure-common-1.1.27 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-automl-core-1.26.0 azureml-core-1.26.0 azureml-dataprep-2.13.2 azureml-dataprep-native-32.0.0 azureml-dataprep-rslex-1.11.2 azureml-dataset-runtime-1.26.0 azureml-pipeline-1.26.0 azureml-pipeline-core-1.26.0 azureml-pipeline-steps-1.26.0 azureml-sdk-1.26.0 azureml-telemetry-1.26.0 azureml-train-1.26.0 azureml-train-automl-client-1.26.0 azureml-train-core-1.26.0 azureml-train-restclients-hyperdrive-1.26.0 backports.tempfile-1.0 backports.weakref-1.0.post1 contextlib2-0.6.0.post1 distro-1.5.0 dotnetcore2-2.1.20 fusepy-3.0.1 importlib-metadata-4.0.0 jeepney-0.6.0 jsonpickle-2.0.0 msal-1.11.0 msal-extensions-0.2.2 msrestazure-0.6.4 ndg-httpsclient-0.5.1 pandas-1.1.0 pathspec-0.8.1 portalocker-1.7.1 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 zipp-3.4.1\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting pandas==1.1.0\n  Downloading pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\nCollecting azureml-sdk\n  Downloading azureml_sdk-1.26.0-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from pandas==1.1.0) (2.8.1)\nRequirement already satisfied: pytz&gt;=2017.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from pandas==1.1.0) (2019.3)\nRequirement already satisfied: numpy&gt;=1.15.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from pandas==1.1.0) (1.18.1)\nCollecting azureml-dataset-runtime[fuse]~=1.26.0\n  Downloading azureml_dataset_runtime-1.26.0-py3-none-any.whl (3.4 kB)\nCollecting azureml-train~=1.26.0\n  Downloading azureml_train-1.26.0-py3-none-any.whl (3.3 kB)\nCollecting azureml-train-automl-client~=1.26.0\n  Downloading azureml_train_automl_client-1.26.0-py3-none-any.whl (119 kB)\nCollecting azureml-pipeline~=1.26.0\n  Downloading azureml_pipeline-1.26.0-py3-none-any.whl (3.7 kB)\nCollecting azureml-core~=1.26.0\n  Downloading azureml_core-1.26.0-py3-none-any.whl (2.2 MB)\nRequirement already satisfied: six&gt;=1.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas==1.1.0) (1.14.0)\nCollecting azureml-dataprep&lt;2.14.0a,&gt;=2.13.0a\n  Downloading azureml_dataprep-2.13.2-py3-none-any.whl (39.4 MB)\nRequirement already satisfied: pyarrow&lt;2.0.0,&gt;=0.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-dataset-runtime[fuse]~=1.26.0-&gt;azureml-sdk) (1.0.1)\nCollecting fusepy&lt;4.0.0,&gt;=3.0.1; extra == &#34;fuse&#34;\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting azureml-train-core~=1.26.0\n  Downloading azureml_train_core-1.26.0-py3-none-any.whl (8.6 MB)\nCollecting azureml-telemetry~=1.26.0\n  Downloading azureml_telemetry-1.26.0-py3-none-any.whl (30 kB)\nCollecting azureml-automl-core~=1.26.0\n  Downloading azureml_automl_core-1.26.0-py3-none-any.whl (200 kB)\nCollecting azureml-pipeline-core~=1.26.0\n  Downloading azureml_pipeline_core-1.26.0-py3-none-any.whl (309 kB)\nCollecting azureml-pipeline-steps~=1.26.0\n  Downloading azureml_pipeline_steps-1.26.0-py3-none-any.whl (68 kB)\nCollecting jsonpickle\n  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting azure-common&gt;=1.1.12\n  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: PyJWT&lt;3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (2.0.1)\nCollecting azure-mgmt-keyvault&lt;7.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting azure-mgmt-authorization&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting ruamel.yaml&gt;=0.15.35\n  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\nRequirement already satisfied: pyopenssl&lt;21.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (19.1.0)\nCollecting azure-mgmt-containerregistry&gt;=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nRequirement already satisfied: msrest&gt;=0.5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (0.6.19)\nRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (2.8)\nRequirement already satisfied: urllib3&gt;=1.23 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (1.25.8)\nCollecting azure-mgmt-resource&lt;15.0.0,&gt;=1.2.1\n  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nRequirement already satisfied: jmespath in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (0.10.0)\nCollecting azure-mgmt-storage&lt;16.0.0,&gt;=1.5.0\n  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting adal&gt;=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting msrestazure&gt;=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.19.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (2.22.0)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting azure-graphrbac&lt;1.0.0,&gt;=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting SecretStorage\n  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: docker in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-core~=1.26.0-&gt;azureml-sdk) (4.4.1)\nCollecting azure-identity&lt;1.5.0,&gt;=1.2.0\n  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\nCollecting azureml-dataprep-native&lt;33.0.0,&gt;=32.0.0\n  Downloading azureml_dataprep_native-32.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\nCollecting azureml-dataprep-rslex&lt;1.12.0a,&gt;=1.11.0dev0\n  Downloading azureml_dataprep_rslex-1.11.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\nRequirement already satisfied: cloudpickle&lt;2.0.0,&gt;=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azureml-dataprep&lt;2.14.0a,&gt;=2.13.0a-&gt;azureml-dataset-runtime[fuse]~=1.26.0-&gt;azureml-sdk) (1.4.1)\nCollecting dotnetcore2&lt;3.0.0,&gt;=2.1.14\n  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\nCollecting azureml-train-restclients-hyperdrive~=1.26.0\n  Downloading azureml_train_restclients_hyperdrive-1.26.0-py3-none-any.whl (19 kB)\nCollecting applicationinsights\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\nCollecting importlib-metadata; python_version &lt; &#34;3.8&#34;\n  Downloading importlib_metadata-4.0.0-py3-none-any.whl (16 kB)\nCollecting ruamel.yaml.clib&gt;=0.1.2; platform_python_implementation == &#34;CPython&#34; and python_version &lt; &#34;3.10&#34;\n  Downloading ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547 kB)\nRequirement already satisfied: isodate&gt;=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (0.6.0)\nRequirement already satisfied: requests-oauthlib&gt;=0.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (1.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (2020.12.5)\nRequirement already satisfied: cffi!=1.11.3,&gt;=1.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (1.14.0)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nRequirement already satisfied: idna&lt;2.9,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.19.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (2.8)\nRequirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.19.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (3.0.4)\nRequirement already satisfied: pyasn1&gt;=0.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from ndg-httpsclient-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (0.4.8)\nCollecting jeepney&gt;=0.6\n  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from docker-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (0.56.0)\nRequirement already satisfied: azure-core&lt;2.0.0,&gt;=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from azure-identity&lt;1.5.0,&gt;=1.2.0-&gt;azureml-dataprep&lt;2.14.0a,&gt;=2.13.0a-&gt;azureml-dataset-runtime[fuse]~=1.26.0-&gt;azureml-sdk) (1.10.0)\nCollecting msal&lt;2.0.0,&gt;=1.3.0\n  Downloading msal-1.11.0-py2.py3-none-any.whl (63 kB)\nCollecting msal-extensions~=0.2.2\n  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\nCollecting distro&gt;=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\nRequirement already satisfied: typing-extensions&gt;=3.6.4; python_version &lt; &#34;3.8&#34; in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;jsonpickle-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (3.7.4.3)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.5.0-&gt;msrest&gt;=0.5.1-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (3.1.0)\nRequirement already satisfied: pycparser in /local_disk0/.ephemeral_nfs/envs/pythonEnv-2512d8d9-1e4e-48dc-815f-9c62c232c72d/lib/python3.7/site-packages (from cffi!=1.11.3,&gt;=1.8-&gt;cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,&lt;4.0.0-&gt;azureml-core~=1.26.0-&gt;azureml-sdk) (2.19)\nCollecting portalocker~=1.0; platform_system != &#34;Windows&#34;\n  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\nBuilding wheels for collected packages: fusepy\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status &#39;done&#39;\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=de34d723a9f01b43a629a83228d7ccd7794a9c1857f2413df586e49f19adadbc\n  Stored in directory: /root/.cache/pip/wheels/89/07/84/a5ebfafeefbbc56ceda9d6935a54a8be7a4eccf4ea7e9bf980\nSuccessfully built fusepy\nERROR: petastorm 0.9.7 requires pyspark&gt;=2.1.0, which is not installed.\nERROR: mlflow 1.13.1 requires alembic&lt;=1.4.1, which is not installed.\nERROR: mlflow 1.13.1 requires prometheus-flask-exporter, which is not installed.\nERROR: mlflow 1.13.1 requires sqlalchemy, which is not installed.\nInstalling collected packages: pandas, msal, portalocker, msal-extensions, azure-identity, azureml-dataprep-native, azureml-dataprep-rslex, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, adal, msrestazure, azureml-train-restclients-hyperdrive, applicationinsights, zipp, importlib-metadata, jsonpickle, azure-common, azure-mgmt-keyvault, azure-mgmt-authorization, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-containerregistry, azure-mgmt-resource, backports.weakref, backports.tempfile, azure-mgmt-storage, pathspec, contextlib2, ndg-httpsclient, azure-graphrbac, jeepney, SecretStorage, azureml-core, azureml-telemetry, azureml-train-core, azureml-train, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-core, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.0.1\n    Uninstalling pandas-1.0.1:\n      Successfully uninstalled pandas-1.0.1\nSuccessfully installed SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.9 azure-common-1.1.27 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-automl-core-1.26.0 azureml-core-1.26.0 azureml-dataprep-2.13.2 azureml-dataprep-native-32.0.0 azureml-dataprep-rslex-1.11.2 azureml-dataset-runtime-1.26.0 azureml-pipeline-1.26.0 azureml-pipeline-core-1.26.0 azureml-pipeline-steps-1.26.0 azureml-sdk-1.26.0 azureml-telemetry-1.26.0 azureml-train-1.26.0 azureml-train-automl-client-1.26.0 azureml-train-core-1.26.0 azureml-train-restclients-hyperdrive-1.26.0 backports.tempfile-1.0 backports.weakref-1.0.post1 contextlib2-0.6.0.post1 distro-1.5.0 dotnetcore2-2.1.20 fusepy-3.0.1 importlib-metadata-4.0.0 jeepney-0.6.0 jsonpickle-2.0.0 msal-1.11.0 msal-extensions-0.2.2 msrestazure-0.6.4 ndg-httpsclient-0.5.1 pandas-1.1.0 pathspec-0.8.1 portalocker-1.7.1 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 zipp-3.4.1\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Good to read:\n\n* http://steventhornton.ca/blog/hyperparameter-tuning-with-hyperopt-in-python.html\n* https://stackoverflow.com/questions/53579444/efficient-text-preprocessing-using-pyspark-clean-tokenize-stopwords-stemming"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"803454f1-3397-4f2b-ab29-1aba6ace3185"}}},{"cell_type":"markdown","source":["# Prepare data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e275724d-869b-4449-93c8-763feca31242"}}},{"cell_type":"code","source":["from pyspark.ml.feature import StopWordsRemover\nfrom nltk.stem.snowball import SnowballStemmer\nfrom pyspark.sql.types import ArrayType, StringType\nfrom pyspark.sql.functions import regexp_replace, col, split, udf\n\n@udf(StringType())\ndef concat_strings(col):\n  return \" \".join(col)\n\ndef transform_tweet_data():\n    # load\n    data = spark.read.csv(\"dbfs:/FileStore/tweets/trump_insult_tweets_2014_to_2021.csv\", header=True)\n    # select\n    data = data.select(split(\"tweet\", \" \").alias(\"tweet\"), \"target\").dropna()\n    # remove stopword\n    remover = StopWordsRemover(inputCol='tweet', outputCol='tweet_clean')\n    data = remover.transform(data)\n    # stem\n    stemmer = SnowballStemmer(language='english')\n    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n    data = data.withColumn(\"tweet_stemmed\", stemmer_udf(\"tweet_clean\")).select('target', 'tweet_stemmed')\n    # clean\n    data = data.withColumn(\"tweet\", regexp_replace(concat_strings(\"tweet_stemmed\"), '\"', \"\")).select(\"tweet\", \"target\")\n    \n    return data\n\ndata_pd = transform_tweet_data().toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39d1b449-8753-40f2-b2de-f95e289106b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Split Dataframe in train and test"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"291d9deb-fa2c-44bf-b330-d3dccdbc3de5"}}},{"cell_type":"code","source":["train = data_pd.groupby('target').sample(frac = 0.8)\ntest = data_pd.drop(train.index)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2ddb5d1-fd68-4d2e-83aa-fdb80815fe19"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Hyperparameter optimization"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9afa37ff-48f9-46b1-bd7f-1f1b265f6476"}}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom hyperopt import hp, STATUS_OK\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\nimport mlflow\n\nsearch_space = {\n  'min_class_frequency': hp.randint('min_class_frequency', 50, 100),\n  'n_estimators': hp.randint('n_estimators', 5, 120),\n  'min_df': hp.randint('min_df', 1, 10),\n  'max_df': hp.uniform('max_df', 0.4, 0.8),\n  'ngram_min': hp.randint('ngram_min', 2, 4),\n  'ngram_max': hp.randint('ngram_max', 4, 10),\n}\n\ndef objective(params):\n    n_estimators = params[\"n_estimators\"]\n    min_df = params[\"min_df\"]\n    max_df = params[\"max_df\"]\n    ngram_min = params[\"ngram_min\"]\n    ngram_max = params[\"ngram_max\"]\n    min_class_frequency = params[\"min_class_frequency\"]\n    \n    # https://stackoverflow.com/questions/30485151/python-pandas-exclude-rows-below-a-certain-frequency-count\n    filtered = train.groupby('target').filter(lambda x: len(x) >= min_class_frequency)\n    \n    vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(ngram_min, ngram_max), min_df=min_df, max_df=max_df)\n    X = vec.fit_transform(filtered['tweet'])\n\n    y = filtered[\"target\"]\n    \n    clf = RandomForestClassifier(n_estimators=n_estimators)\n                                 \n    accuracy=cross_val_score(clf, X, y, scoring=\"accuracy\").mean()\n    \n    return {'loss': -accuracy, 'status': STATUS_OK}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae08246d-6ce6-497e-9781-3797d31f3e46"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from hyperopt import fmin, tpe, SparkTrials\nimport mlflow\n\nmlflow.set_experiment(\"/Users/{}/demos/trump-tweets/Trump-tweets-insults\".format(dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"adb-username\")))\n#https://docs.databricks.com/applications/machine-learning/automl-hyperparam-tuning/hyperopt-concepts.html#id3\nwith mlflow.start_run(run_name=\"RandomForestClassifier Hyperopt\", nested=True):\n    argmin = fmin(fn=objective,\n                  space=search_space,\n                  algo=tpe.suggest,\n                  max_evals=18,\n                  trials=SparkTrials(parallelism=6))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c1a45f1-8f38-451b-b047-f98e45a82349"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Hyperopt with SparkTrials will automatically track trials in MLflow. To view the MLflow experiment associated with the notebook, click the &#39;Runs&#39; icon in the notebook context bar on the upper right. There, you can view all runs.\nTo view logs from trials, please check the Spark executor logs. To view executor logs, expand &#39;Spark Jobs&#39; above until you see the (i) icon next to the stage from the trial job. Click it and find the list of tasks. Click the &#39;stderr&#39; link for a task to view trial logs.\n\r  0%|          | 0/18 [00:00&lt;?, ?trial/s, best loss=?]\r  6%|▌         | 1/18 [00:23&lt;06:38, 23.46s/trial, best loss: -0.7446014645517416]\r 11%|█         | 2/18 [02:55&lt;16:34, 62.14s/trial, best loss: -0.7678510437772694]\r 17%|█▋        | 3/18 [03:42&lt;14:24, 57.61s/trial, best loss: -0.7678510437772694]\r 22%|██▏       | 4/18 [04:09&lt;11:15, 48.26s/trial, best loss: -0.7705726458193697]\r 28%|██▊       | 5/18 [04:45&lt;09:39, 44.59s/trial, best loss: -0.7705726458193697]\r 33%|███▎      | 6/18 [05:42&lt;09:41, 48.50s/trial, best loss: -0.7723861911695595]\r 39%|███▉      | 7/18 [07:57&lt;13:37, 74.35s/trial, best loss: -0.785128205128205] \r 44%|████▍     | 8/18 [08:14&lt;09:31, 57.15s/trial, best loss: -0.785128205128205]\r 50%|█████     | 9/18 [08:52&lt;07:42, 51.42s/trial, best loss: -0.785128205128205]\r 56%|█████▌    | 10/18 [09:44&lt;06:52, 51.61s/trial, best loss: -0.785128205128205]\r 61%|██████    | 11/18 [11:26&lt;07:47, 66.76s/trial, best loss: -0.785128205128205]\r 67%|██████▋   | 12/18 [12:08&lt;05:56, 59.34s/trial, best loss: -0.785128205128205]\r 72%|███████▏  | 13/18 [12:10&lt;03:30, 42.14s/trial, best loss: -0.785128205128205]\r 78%|███████▊  | 14/18 [13:59&lt;04:07, 61.93s/trial, best loss: -0.785128205128205]\r 83%|████████▎ | 15/18 [14:25&lt;02:33, 51.16s/trial, best loss: -0.785128205128205]\r 89%|████████▉ | 16/18 [15:15&lt;01:41, 50.83s/trial, best loss: -0.785128205128205]\r 94%|█████████▍| 17/18 [16:16&lt;00:53, 53.89s/trial, best loss: -0.785128205128205]\r100%|██████████| 18/18 [17:09&lt;00:00, 53.64s/trial, best loss: -0.785128205128205]\r100%|██████████| 18/18 [17:09&lt;00:00, 57.18s/trial, best loss: -0.785128205128205]\nTotal Trials: 18: 18 succeeded, 0 failed, 0 cancelled.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Hyperopt with SparkTrials will automatically track trials in MLflow. To view the MLflow experiment associated with the notebook, click the &#39;Runs&#39; icon in the notebook context bar on the upper right. There, you can view all runs.\nTo view logs from trials, please check the Spark executor logs. To view executor logs, expand &#39;Spark Jobs&#39; above until you see the (i) icon next to the stage from the trial job. Click it and find the list of tasks. Click the &#39;stderr&#39; link for a task to view trial logs.\n\r  0%|          | 0/18 [00:00&lt;?, ?trial/s, best loss=?]\r  6%|▌         | 1/18 [00:23&lt;06:38, 23.46s/trial, best loss: -0.7446014645517416]\r 11%|█         | 2/18 [02:55&lt;16:34, 62.14s/trial, best loss: -0.7678510437772694]\r 17%|█▋        | 3/18 [03:42&lt;14:24, 57.61s/trial, best loss: -0.7678510437772694]\r 22%|██▏       | 4/18 [04:09&lt;11:15, 48.26s/trial, best loss: -0.7705726458193697]\r 28%|██▊       | 5/18 [04:45&lt;09:39, 44.59s/trial, best loss: -0.7705726458193697]\r 33%|███▎      | 6/18 [05:42&lt;09:41, 48.50s/trial, best loss: -0.7723861911695595]\r 39%|███▉      | 7/18 [07:57&lt;13:37, 74.35s/trial, best loss: -0.785128205128205] \r 44%|████▍     | 8/18 [08:14&lt;09:31, 57.15s/trial, best loss: -0.785128205128205]\r 50%|█████     | 9/18 [08:52&lt;07:42, 51.42s/trial, best loss: -0.785128205128205]\r 56%|█████▌    | 10/18 [09:44&lt;06:52, 51.61s/trial, best loss: -0.785128205128205]\r 61%|██████    | 11/18 [11:26&lt;07:47, 66.76s/trial, best loss: -0.785128205128205]\r 67%|██████▋   | 12/18 [12:08&lt;05:56, 59.34s/trial, best loss: -0.785128205128205]\r 72%|███████▏  | 13/18 [12:10&lt;03:30, 42.14s/trial, best loss: -0.785128205128205]\r 78%|███████▊  | 14/18 [13:59&lt;04:07, 61.93s/trial, best loss: -0.785128205128205]\r 83%|████████▎ | 15/18 [14:25&lt;02:33, 51.16s/trial, best loss: -0.785128205128205]\r 89%|████████▉ | 16/18 [15:15&lt;01:41, 50.83s/trial, best loss: -0.785128205128205]\r 94%|█████████▍| 17/18 [16:16&lt;00:53, 53.89s/trial, best loss: -0.785128205128205]\r100%|██████████| 18/18 [17:09&lt;00:00, 53.64s/trial, best loss: -0.785128205128205]\r100%|██████████| 18/18 [17:09&lt;00:00, 57.18s/trial, best loss: -0.785128205128205]\nTotal Trials: 18: 18 succeeded, 0 failed, 0 cancelled.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["argmin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b870be6e-b240-4e59-8cda-53f3ffd5cb4d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[68]: {&#39;max_df&#39;: 0.6,\n &#39;min_class_frequency&#39;: 91,\n &#39;min_df&#39;: 1,\n &#39;n_estimators&#39;: 100,\n &#39;ngram_max&#39;: 7,\n &#39;ngram_min&#39;: 3}</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[68]: {&#39;max_df&#39;: 0.6,\n &#39;min_class_frequency&#39;: 91,\n &#39;min_df&#39;: 1,\n &#39;n_estimators&#39;: 100,\n &#39;ngram_max&#39;: 7,\n &#39;ngram_min&#39;: 3}</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Train the model using the best parameters"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e212436-f19b-4fc5-8c08-f897e4659ad5"}}},{"cell_type":"code","source":["argmin = {'max_df': 0.6,\n 'min_class_frequency': 50,\n 'min_df': 5,\n 'n_estimators': 100,\n 'ngram_max': 7,\n 'ngram_min': 3}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04c5cf4a-2ddb-4be0-a1f5-2f5df9db9163"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Using sklearn's pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49041e2e-b0aa-4173-9926-ddcd922749cf"}}},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nimport mlflow\n\nmlflow.set_experiment(\"/Users/{}/demos/trump-tweets/Trump-tweets-insults\".format(dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"adb-username\")))\nwith mlflow.start_run(run_name=\"RandomForestClassifier Best Parameter Pipeline\") as run:\n    n_estimators = argmin[\"n_estimators\"]\n    min_df = argmin[\"min_df\"]\n    max_df = argmin[\"max_df\"]\n    ngram_min = argmin[\"ngram_min\"]\n    ngram_max = argmin[\"ngram_max\"]\n    min_class_frequency = argmin[\"min_class_frequency\"]\n\n    filtered = train.groupby('target').filter(lambda x: len(x) >= min_class_frequency)\n    X = filtered[['tweet']]\n    y = filtered[\"target\"]\n    \n    feature_pipe = Pipeline([\n        ('tfidf', TfidfVectorizer(analyzer='char_wb', ngram_range=(ngram_min, ngram_max), min_df=min_df, max_df=max_df))\n    ])\n\n    feature_preprocessing_pipe = ColumnTransformer([\n        (\"features_preprocessor\", feature_pipe, 'tweet')\n    ])\n\n    pipe = Pipeline([\n      ('feature_preprocessor', feature_preprocessing_pipe),\n      ('estimator', RandomForestClassifier(n_estimators=n_estimators))\n    ])\n\n    pipe.fit(X, y)\n    mlflow.sklearn.log_model(pipe, \"trump_tweets_pipe\")\n\n    test_filtered = test[test['target'].isin(filtered['target'].unique())]\n    acc = pipe.score(test_filtered[['tweet']], test_filtered['target'])\n    mlflow.log_metric('accuracy', acc)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3748e9b-7059-43bf-894e-1993094f6c51"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["data = [\"The media is spreading fake news!\"]\nimport pandas as pd\npipe.predict(pd.DataFrame(data, columns=['tweet']))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c81fd1ea-3ebb-4597-968c-69b8ced11086"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: array([&#39;the-media&#39;], dtype=object)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: array([&#39;the-media&#39;], dtype=object)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Use logged model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cd1d826-5563-4af9-8791-2bef47771261"}}},{"cell_type":"code","source":["logged_model = 'runs:/{}/trump_tweets_pipe'.format(run.info.run_id)\nloaded_model = mlflow.pyfunc.load_model(logged_model)\ndata = [\"The media is spreading fake news!\"]\nimport pandas as pd\nloaded_model.predict(pd.DataFrame(data, columns=['tweet']))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dea6de49-b5c9-40db-98df-c1e96347712b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[102]: array([&#39;the-media&#39;], dtype=object)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[102]: array([&#39;the-media&#39;], dtype=object)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Register model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b077f94c-8940-4d38-9d8e-8e1b98dfa61b"}}},{"cell_type":"code","source":["model_uri = \"runs:/{}/trump_tweets_pipe\".format(run.info.run_id)\nmv = mlflow.register_model(model_uri, \"TrumpTweetsClassifier\")\nprint(\"Name: {}\".format(mv.name))\nprint(\"Version: {}\".format(mv.version))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51c08364-c26c-409c-ab06-c2ad48a7e647"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Registered model &#39;TrumpTweetsClassifier&#39; already exists. Creating a new version of this model...\n2021/04/19 10:09:13 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: TrumpTweetsClassifier, version 4\nCreated version &#39;4&#39; of model &#39;TrumpTweetsClassifier&#39;.\nName: TrumpTweetsClassifier\nVersion: 4\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registered model &#39;TrumpTweetsClassifier&#39; already exists. Creating a new version of this model...\n2021/04/19 10:09:13 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: TrumpTweetsClassifier, version 4\nCreated version &#39;4&#39; of model &#39;TrumpTweetsClassifier&#39;.\nName: TrumpTweetsClassifier\nVersion: 4\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Deploy model for realtime inferencing on Azure ACI/AKS\n\nAKS for production or MLFlow Model Serving for dev, too."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d22aef9-c7c4-4d12-a206-ff709e5f9cf3"}}},{"cell_type":"code","source":["import mlflow.azureml\nfrom azureml.core import Workspace\nfrom azureml.core.webservice import AksWebservice, AciWebservice, Webservice\nfrom azureml.core.compute import AksCompute\n\n# Load or create an Azure ML Workspace\nworkspace_name = \"mlw-test\"\nsubscription_id = dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"sandbox-subscription-id\")\nresource_group = \"rg-ai-test\"\nlocation = \"westeurope\"\n\nazure_workspace = Workspace.create(name=workspace_name,\n                                   subscription_id=subscription_id,\n                                   resource_group=resource_group,\n                                   location=location,\n                                   create_resource_group=True,\n                                   exist_ok=True)\n\ndeploy_config = AksWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 8, compute_target_name='trump-tweets-inf')\n\n# Create an Azure Container Instance webservice for an MLflow model\nazure_service, azure_model = mlflow.azureml.deploy(model_uri=\"runs:/{}/trump_tweets_pipe\".format(run.info.run_id),\n                                                   service_name=\"trump-tweets-scoring-adb\",\n                                                   deployment_config=deploy_config,\n                                                   workspace=azure_workspace,\n                                                   synchronous=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f27d3141-ffb8-4043-852b-ef4ee6387f88"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Registering model mlflow-model-2a2abc17acb4422f832\n2021/04/19 10:39:48 INFO mlflow.azureml: Registered an Azure Model with name: `mlflow-model-2a2abc17acb4422f832` and version: `1`\n2021/04/19 10:39:56 INFO mlflow.azureml: Deploying an Azure Webservice with name: `trump-tweets-scoring-adb`\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2021-04-19 10:39:57+00:00 Creating Container Registry if not exists.\n2021-04-19 10:39:57+00:00 Registering the environment.\n2021-04-19 10:39:58+00:00 Use the existing image.\n2021-04-19 10:40:01+00:00 Creating resources in AKS.\n2021-04-19 10:40:01+00:00 Submitting deployment to compute.\n2021-04-19 10:40:01+00:00 Checking the status of deployment trump-tweets-scoring-adb..\n2021-04-19 10:40:51+00:00 Checking the status of inference endpoint trump-tweets-scoring-adb.\nSucceeded\nAKS service creation operation finished, operation &#34;Succeeded&#34;\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model mlflow-model-2a2abc17acb4422f832\n2021/04/19 10:39:48 INFO mlflow.azureml: Registered an Azure Model with name: `mlflow-model-2a2abc17acb4422f832` and version: `1`\n2021/04/19 10:39:56 INFO mlflow.azureml: Deploying an Azure Webservice with name: `trump-tweets-scoring-adb`\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2021-04-19 10:39:57+00:00 Creating Container Registry if not exists.\n2021-04-19 10:39:57+00:00 Registering the environment.\n2021-04-19 10:39:58+00:00 Use the existing image.\n2021-04-19 10:40:01+00:00 Creating resources in AKS.\n2021-04-19 10:40:01+00:00 Submitting deployment to compute.\n2021-04-19 10:40:01+00:00 Checking the status of deployment trump-tweets-scoring-adb..\n2021-04-19 10:40:51+00:00 Checking the status of inference endpoint trump-tweets-scoring-adb.\nSucceeded\nAKS service creation operation finished, operation &#34;Succeeded&#34;\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Test endpoints"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f68e3c9b-4bb3-4092-b254-fc25d24d1b2f"}}},{"cell_type":"code","source":["import pandas as pd\nsample_request = pd.DataFrame([\"The media is spreading fake news!\"], columns=[\"tweet\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04c7b7aa-e36b-4e5e-bc95-8a731386fab6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Test ACI/AKS endpoint"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f89bbbd-393e-4687-bc60-539faafa9283"}}},{"cell_type":"code","source":["import requests\nimport json\n \ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n    \n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=json.dumps(inputs), headers=headers)\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  #return preds\n\nquery_endpoint_example(\"http://20.76.44.123:80/api/v1/service/trump-tweets-scoring-adb/score\",\n                       sample_request.to_dict(orient='split'),\n                       dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"trump-tweets-scoring-aml\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f7a9a5d-f955-49bf-bcdb-24193d5284b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Sending batch prediction request with inputs: {&#39;index&#39;: [0], &#39;columns&#39;: [&#39;tweet&#39;], &#39;data&#39;: [[&#39;The media is spreading fake news!&#39;]]}\nReceived response: [&#39;the-media&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Sending batch prediction request with inputs: {&#39;index&#39;: [0], &#39;columns&#39;: [&#39;tweet&#39;], &#39;data&#39;: [[&#39;The media is spreading fake news!&#39;]]}\nReceived response: [&#39;the-media&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Test MLFLow model serving"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98d00cbd-a975-4403-9e25-a5bb310938e3"}}},{"cell_type":"code","source":["pd.DataFrame.to_json(sample_request, orient='records')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1084f29-c660-4b40-a5e3-c42bfd7f797e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[29]: &#39;[{&#34;tweet&#34;:&#34;The media is spreading fake news!&#34;}]&#39;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[29]: &#39;[{&#34;tweet&#34;:&#34;The media is spreading fake news!&#34;}]&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eaa59b5e-2e04-4e51-9d57-a2b33faf6015"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"trump-tweet-pipeline","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2,"experimentId":"1819076092413600"},"language":"python","widgets":{},"notebookOrigID":3532861101179795}},"nbformat":4,"nbformat_minor":0}
